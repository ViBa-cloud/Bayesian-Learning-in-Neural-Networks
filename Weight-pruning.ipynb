{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0b40197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# sns.set_theme(context='talk', style='whitegrid', palette='colorblind')\n",
    "# from classes.layers import BayesLinearMixture\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from torch.nn import Module, Parameter\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3e6d978",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "# training_data = datasets.MNIST(root='data', train=True, download=True, transform=ToTensor())\n",
    "# training_set, validation_set = torch.utils.data.random_split(training_data, [50000, 10000])\n",
    "test_data = datasets.MNIST(root='data', train=False, download=True, transform=ToTensor())\n",
    "\n",
    "\n",
    "# training_loader = DataLoader(training_set, batch_size=batch_size, shuffle=True)\n",
    "# validation_loader = DataLoader(validation_set, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# print(type(test_data[0][0][0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18c60d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesLinearMixture(Module):\n",
    "    r\"\"\"\n",
    "    Applies Bayesian Linear\n",
    "    Arguments:\n",
    "        prior_mu (Float): mean of prior normal distribution.\n",
    "        prior_sigma (Float): sigma of prior normal distribution.\n",
    "    .. note:: other arguments are following linear of pytorch 1.2.0.\n",
    "    https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/linear.py\n",
    "    \n",
    "    \"\"\"\n",
    "    __constants__ = ['prior_mu', 'prior_sigma', 'bias', 'in_features', 'out_features']\n",
    "\n",
    "    def __init__(self, prior_mu1, prior_sigma1, prior_mu2, prior_sigma2, pi, in_features, out_features):\n",
    "        super(BayesLinearMixture, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        self.prior_mu1 = prior_mu1\n",
    "        self.prior_sigma1 = prior_sigma1\n",
    "        self.prior_log_sigma1 = math.log(prior_sigma1)\n",
    "\n",
    "        self.prior_mu2 = prior_mu2\n",
    "        self.prior_sigma2 = prior_sigma2\n",
    "        self.prior_log_sigma2 = math.log(prior_sigma2)\n",
    "\n",
    "        self.pi = pi\n",
    "\n",
    "        self.weight_mu = Parameter(torch.Tensor(out_features, in_features))\n",
    "#         self.weight_log_sigma = Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.weight_rho = Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.register_buffer('weight_eps', None)\n",
    "\n",
    "#         if bias is None or bias is False :\n",
    "#             self.bias = False\n",
    "#         else :\n",
    "#             self.bias = True\n",
    "\n",
    "#         if self.bias:\n",
    "#             self.bias_mu = Parameter(torch.Tensor(out_features))\n",
    "#             self.bias_log_sigma = Parameter(torch.Tensor(out_features))\n",
    "#             self.register_buffer('bias_eps', None)\n",
    "#         else:\n",
    "#             self.register_parameter('bias_mu', None)\n",
    "#             self.register_parameter('bias_log_sigma', None)\n",
    "#             self.register_buffer('bias_eps', None)\n",
    "            \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        # Initialization method of Adv-BNN\n",
    "        stdv = 1. / math.sqrt(self.weight_mu.size(1))\n",
    "        self.weight_mu.data.uniform_(-stdv, stdv)\n",
    "        self.weight_rho.data.fill_(self.prior_log_sigma1)\n",
    "#         if self.bias :\n",
    "#             self.bias_mu.data.uniform_(-stdv, stdv)\n",
    "#             self.bias_log_sigma.data.fill_(self.prior_log_sigma1)\n",
    "  \n",
    "    def freeze(self) :\n",
    "        self.weight_eps = torch.randn_like(self.weight_log_sigma)\n",
    "#         if self.bias :\n",
    "#             self.bias_eps = torch.randn_like(self.bias_log_sigma)\n",
    "        \n",
    "    def unfreeze(self) :\n",
    "        self.weight_eps = None\n",
    "#         if self.bias :\n",
    "#             self.bias_eps = None \n",
    "            \n",
    "    def forward(self, input):\n",
    "        r\"\"\"\n",
    "        Overriden.\n",
    "        \"\"\"\n",
    "#         if self.weight_eps is None :\n",
    "        eps = torch.torch.randn_like(self.weight_rho)\n",
    "        self.weight = self.weight_mu + torch.log1p(torch.exp(self.weight_rho)) * eps\n",
    "#         else :\n",
    "#             self.weight = self.weight_mu + torch.exp(self.weight_log_sigma) * self.weight_eps\n",
    "        \n",
    "#         if self.bias:\n",
    "#             if self.bias_eps is None :\n",
    "#                 bias = self.bias_mu + torch.exp(self.bias_log_sigma) * torch.randn_like(self.bias_log_sigma)\n",
    "#             else :\n",
    "#                 bias = self.bias_mu + torch.exp(self.bias_log_sigma) * self.bias_eps                \n",
    "#         else :\n",
    "#             bias = None\n",
    "\n",
    "        return F.linear(input, self.weight, bias=None)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        r\"\"\"\n",
    "        Overriden.\n",
    "        \"\"\"\n",
    "        return 'prior_mu1={}, prior_sigma1={}, prior_mu2={}, prior_sigma2={}, in_features={}, out_features={}'.format(self.prior_mu1, self.prior_sigma1, self.prior_mu2, self.prior_sigma2, self.in_features, self.out_features)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03f0c07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 784\n",
    "hidden_dim = 1200\n",
    "num_classes = 10\n",
    "log_sigma1 = -1\n",
    "log_sigma2 = -6\n",
    "pi = 0.75\n",
    "sigma1 = 10 ** log_sigma1\n",
    "sigma2 = 10 ** log_sigma2\n",
    "model = nn.Sequential(\n",
    "    BayesLinearMixture(prior_mu1=0, prior_sigma1=sigma1, prior_mu2=0, prior_sigma2=sigma2, in_features=input_dim, out_features=hidden_dim, pi=pi),\n",
    "    nn.ReLU(),\n",
    "    BayesLinearMixture(prior_mu1=0, prior_sigma1=sigma1, prior_mu2=0, prior_sigma2=sigma2, in_features=hidden_dim, out_features=hidden_dim, pi=pi),\n",
    "    nn.ReLU(),\n",
    "    BayesLinearMixture(prior_mu1=0, prior_sigma1=sigma1, prior_mu2=0, prior_sigma2=sigma2, in_features=hidden_dim, out_features=num_classes, pi=pi),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9482e526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2392800\n"
     ]
    }
   ],
   "source": [
    "signal_to_noise = []\n",
    "directory = \"./models/\"\n",
    "# filename = os.path.join(directory, \"gaussian-mixture-prior\", \"averaging2\", \"pi0.5\", \"sigma21e-6\", \"model_20230408_123457_300\")\n",
    "filename = os.path.join(directory, \"gaussian-mixture-prior\", \"model_20230411_090805_300\")\n",
    "model.load_state_dict(torch.load(filename))\n",
    "model.train(False)\n",
    "\n",
    "for m in model.modules():\n",
    "    if isinstance(m, BayesLinearMixture):\n",
    "        mu = m.weight_mu.data.numpy()\n",
    "        rho = m.weight_rho.data.numpy()\n",
    "        sigma = np.log1p(np.exp(rho))\n",
    "        s2n = np.log(np.abs(mu) / sigma)\n",
    "        s2n = list(s2n.flatten())\n",
    "        signal_to_noise.extend(s2n)\n",
    "\n",
    "print(len(signal_to_noise))\n",
    "signal_to_noise = np.array(signal_to_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33de37ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47856\n"
     ]
    }
   ],
   "source": [
    "signal_to_noise.sort()\n",
    "index = int(len(signal_to_noise) * 0.98)\n",
    "threshold_val = signal_to_noise[index]\n",
    "\n",
    "num_weights = 0\n",
    "model.train(False)\n",
    "\n",
    "for m in model.modules():\n",
    "    if isinstance(m, BayesLinearMixture):\n",
    "        m.weight_mu.requires_grad_(False)\n",
    "        m.weight_rho.requires_grad_(False)\n",
    "\n",
    "        mu = m.weight_mu.data.numpy()\n",
    "        rho = m.weight_rho.data.numpy()\n",
    "        sigma = np.log1p(np.exp(rho) )\n",
    "        s2n = np.log(np.abs(mu) / sigma + 1e-6)        \n",
    "        mask = (s2n>=threshold_val)\n",
    "        num_weights += np.sum(mask)\n",
    "        m.weight_mu.data *= mask.astype(float)\n",
    "        m.weight_rho.data += -1e10 * (1-mask).astype(float)\n",
    "        m.weight_mu.data = m.weight_mu.data.float()\n",
    "        m.weight_rho.data = m.weight_rho.data.float()\n",
    "        \n",
    "print(num_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "599e5c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions 4534\n",
      "Error: 54.66\n"
     ]
    }
   ],
   "source": [
    "##### model.train(False)\n",
    "\n",
    "num_iters = 1\n",
    "accuracy = 0.0\n",
    "for _ in range(num_iters):\n",
    "    correct = 0\n",
    "\n",
    "    for i, tdata in enumerate(test_loader):\n",
    "        tinputs, tlabels = tdata\n",
    "        tinputs = tinputs.view(-1, 784)\n",
    "        toutputs = model(tinputs)\n",
    "        _, predicted = torch.max(toutputs, 1)\n",
    "        correct += torch.sum(tlabels == predicted)\n",
    "\n",
    "    accuracy += correct / len(test_data) / num_iters\n",
    "    \n",
    "\n",
    "print(\"Number of correct predictions {}\".format(correct))\n",
    "\n",
    "print(\"Error: {:.2f}\".format(100 - 100 * accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
